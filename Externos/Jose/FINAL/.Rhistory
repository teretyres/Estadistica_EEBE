rm(list=ls())
theta = 2.3 #Parámetro "theta" a estimar usando una muestra
#Función de distribución
frame()
curve(theta/(x^(theta+1)), from=1, to=6, lwd=3, col='red') #Esto cambia
#Simula muestra de n observaciones
n = 20 #Tamaño muestra
xs = exp(rexp(n, theta)) #Valores de X
hist(xs[xs<6], prob=T, add=T, breaks=15)
th_est = n/(sum(log(xs))); th_est #Estimación de theta, esto cambia
#Estimación de theta con m muestras de n observaciones
m = 1*10^4
X_est=rep(m,0)
for(i in 1:m){xs = exp(rexp(n, theta)); th_est[i] = n/(sum(log(xs)))} #Esto cambia
mean(th_est)
Bias = theta/(n-1); Bias
var(th_est)
var_th_est = n^2*theta^2/((n-1)^2*(n-2)); var_th_est #Esto cambia
hist(th_est, prob=TRUE, breaks=15)
rm(list=ls())
theta = 2.3 #Parámetro "theta" a estimar usando una muestra
#Función de distribución
frame()
curve(theta/(x^(theta+1)), from=1, to=6, lwd=3, col='red') #Esto cambia
#Simula muestra de n observaciones
n = 2000 #Tamaño muestra
xs = exp(rexp(n, theta)) #Valores de X
hist(xs[xs<6], prob=T, add=T, breaks=15)
th_est = n/(sum(log(xs))); th_est #Estimación de theta, esto cambia
#Estimación de theta con m muestras de n observaciones
m = 1*10^4
X_est=rep(m,0)
for(i in 1:m){xs = exp(rexp(n, theta)); th_est[i] = n/(sum(log(xs)))} #Esto cambia
mean(th_est)
Bias = theta/(n-1); Bias
var(th_est)
var_th_est = n^2*theta^2/((n-1)^2*(n-2)); var_th_est #Esto cambia
hist(th_est, prob=TRUE, breaks=15)
curve(dnorm(x,theta,sqrt(var_th_est)), lwd=3, col='red', add=T)
rm(list=ls())
##Caso 1: sd conocida, dist normal
#El int es; [mean-Zalpha/2*sd/sqrt(n) ; mean+Zalpha/2*sd/sqrt(n)]
gamma = 0.9 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
##Caso 1: sd conocida, dist normal
#El int es; [mean-Zalpha/2*sd/sqrt(n) ; mean+Zalpha/2*sd/sqrt(n)]
gamma = 0.97 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
##Caso 1: sd conocida, dist normal
#El int es; [mean-Zalpha/2*sd/sqrt(n) ; mean+Zalpha/2*sd/sqrt(n)]
gamma = 0.98 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
Z = qnorm(0.99,0,1); Z #Es Z alpha/2
##Caso 1: sd conocida, dist normal
#El int es; [mean-Zalpha/2*sd/sqrt(n) ; mean+Zalpha/2*sd/sqrt(n)]
gamma = 0.98 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
rm(list=ls())
##Caso 3: t student, mu y sd desconocidos. Usar la var muestral mod s^2 con (n-1)
#El int será: [mean-talpha/2*s/sqrt(n) ; mean+talpha/2*s/sqrt(n)]
gamma = 0.95 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
n = 5 #Tamaño de la muestra, n-1 gl
t = qt(1-alpha/2, n-1); t #Es t alpha/2
rm(list=ls())
##Caso 3: t student, mu y sd desconocidos. Usar la var muestral mod s^2 con (n-1)
#El int será: [mean-talpha/2*s/sqrt(n) ; mean+talpha/2*s/sqrt(n)]
gamma = 0.95 #Nivel de confianza
##Caso 3: t student, mu y sd desconocidos. Usar la var muestral mod s^2 con (n-1)
#El int será: [mean-talpha/2*s/sqrt(n) ; mean+talpha/2*s/sqrt(n)]
gamma = 0.99 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
n = 5 #Tamaño de la muestra, n-1 gl
t = qt(1-alpha/2, n-1); t #Es t alpha/2
rm(list=ls())
##Caso 4: se quiere estimar la varianza (σ^2), se desconoce mu y sd, n cualquiera. Chi cuadrado
#Usar Var quasi muestral s^2=Sum(xi-x)^2/(n-1)
#El int para Var es: [(n-1)*s^2/b ; (n-1)*s^2/a]              ##Estas dos s son s^2(n-1)
#El int para sd es: (sqrt((n-1)*s^2/b) ; sqrt((n-1)*s^2/a))   ##Estas dos s son s^2(n-1)
#El int para Var es: [n*s^2/b ; n*s^2/a]                      ##Estas dos s son s^2(n) = σ^2
#a es el lateral inferior, b el superior
gamma = 0.95
n = 51
gamma = 0.95
n = 51
alpha = 1 - gamma
a = qchisq(alpha/2,n-1,lower.tail=TRUE); a
b = qchisq(alpha/2,n-1,lower.tail=FALSE); b
b = qchisq(1-alpha/2,n-1,lower.tail=TRUE); b
rm(list=ls())
##Caso 1: sd conocida, dist normal
#El int es; [mean-Zalpha/2*sd/sqrt(n) ; mean+Zalpha/2*sd/sqrt(n)]
gamma = 0.99 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
##Caso 1: sd conocida, dist normal
#El int es; [mean-Zalpha/2*sd/sqrt(n) ; mean+Zalpha/2*sd/sqrt(n)]
gamma = 0.9 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
rm(list=ls())
alpha = 0.05 #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
rm(list=ls())
n = 20 #Tamaño de la muestra, n-1 gl
alpha = 0.05 #Nivel de significación
t = qt(1-alpha/2, n-1); t #Es t alpha/2
alpha = 0.1 #Nivel de significación
t = qt(1-alpha/2, n-1); t #Es t alpha/2
alpha = 0.05
a = qchisq(alpha/2,n-1,lower.tail=TRUE); a
b = qchisq(alpha/2,n-1,lower.tail=FALSE); b
rm(list=ls())
rm(list=ls())
##Caso 1: sd conocida, dist normal
#El int es; [mean-Zalpha/2*sd/sqrt(n) ; mean+Zalpha/2*sd/sqrt(n)]
gamma = 0.9 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
alpha = pnorm(Z,0,1); alpha
##Caso 1: sd conocida, dist normal
#El int es; [mean-Zalpha/2*sd/sqrt(n) ; mean+Zalpha/2*sd/sqrt(n)]
gamma = 0.9 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
alpha = pnorm(Z,0,1); alpha
##Caso 1: sd conocida, dist normal
#El int es; [mean-Zalpha/2*sd/sqrt(n) ; mean+Zalpha/2*sd/sqrt(n)]
gamma = 0.9 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
alphaedos = pnorm(Z,0,1)
alpha = alphaedos*2; alpha
##Caso 1: sd conocida, dist normal
#El int es; [mean-Zalpha/2*sd/sqrt(n) ; mean+Zalpha/2*sd/sqrt(n)]
gamma = 0.9 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
alphaedos = pnorm(Z,0,1)
rm(list=ls())
##Caso 1: sd conocida, dist normal
#El int es; [mean-Zalpha/2*sd/sqrt(n) ; mean+Zalpha/2*sd/sqrt(n)]
gamma = 0.9 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
alphaedos = pnorm(Z,0,1)
alpha = (1-alphaedos)*2; alpha
##Caso 1: sd conocida, dist normal
#El int es; [mean-Zalpha/2*sd/sqrt(n) ; mean+Zalpha/2*sd/sqrt(n)]
gamma = 0.98 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
alphaedos = pnorm(Z,0,1)
alpha = (1-alphaedos)*2; alpha
rm(list=ls())
##Caso 1: sd conocida, dist normal
#El int es; [mean-Zalpha/2*sd/sqrt(n) ; mean+Zalpha/2*sd/sqrt(n)]
gamma = 0.98 #Nivel de confianza
alpha = 1 - gamma #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
alphaedos = pnorm(Z,0,1)
alphaprima = (1-alphaedos)*2; alphaprima #Si me dan int y me preguntan alpha
gammaprima = 1-alphaprima; gammaprima#Si me dan int y me preguntan gamma (nivel confianza)
rm(list=ls())
#Var(X)=E(X^2)-(E(X))^2
Z=1,96
#Var(X)=E(X^2)-(E(X))^2
Z=1.96
alphaedos = pnorm(Z,0,1)
alphaprima = (1-alphaedos)*2; alphaprima #Si me dan int y me preguntan alpha
gammaprima = 1-alphaprima; gammaprima#Si me dan int y me preguntan gamma (nivel confianza)
rm(list=ls())
alpha = 0.05 #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
#En hipótesis, se acepta H0 si (como Caso 1):
#Bilateral: Zalpha/2 <= Zobs <= Zalpha/2; con p=2-2F(Zobs), si p >= alpha
#H0: p=p0, H1: p != p0
n = 250
p0 = 0.1
pobs = 0.14
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2
Zobs = (pobs-p0)/sqrt(p0*(1-p0)/n) #Este es el estadístico
f = pnorm(Zobs,0,1) #Es F(Zobs)
p = 2-2*f #Esto es el Valor P, no la probabilidad ni nada que me den
#En hipótesis, se acepta H0 si (como Caso 1):
#Bilateral: Zalpha/2 <= Zobs <= Zalpha/2; con p=2-2F(Zobs), si p >= alpha
#H0: p=p0, H1: p != p0
n = 1225
rm(list=ls())
#En hipótesis, se acepta H0 si (como Caso 1):
#Bilateral: Zalpha/2 <= Zobs <= Zalpha/2; con p=2-2F(Zobs), si p >= alpha
#H0: p=p0, H1: p != p0
n = 1225
p0 = 0.75
pobs = 926/1225
#Unilateral superior: se acepta H0 si Zobs <= Zalpha, o si p >= alpha
#H0: mu <= mu0, H1: p > p0 (rechazo arriba, a la dcha)
Z = qnorm(1-alpha,0,1); Z #Es Z alpha
Zobs = (pobs-p0)/sqrt(p0*(1-p0)/n)
p = 1 - pnorm(Zobs,0,1) #Es p = 1 - F(Zobs)
rm(list=ls())
#En hipótesis, se acepta H0 si:
#Bilateral: Zalpha/2 <= Zobs <= Zalpha/2; con p=2-2F(Zobs), si p >= alpha
#H0: mu = mu0, H1: mu != mu0
alpha = 0.0505
#Unilateral superior: se acepta H0 si Zobs <= Zalpha, o si p >= alpha
#H0: mu <=(=) mu0, H1: mu > mu0 (rechazo arriba, a la dcha)
Z = qnorm(1-alpha,0,1); Z #Es Z alpha
Z = qnorm(0.36,0,1); Z #Es Z alpha/2
Z = qnorm(0.36*2,0,1); Z #Es Z alpha/2
Z = qnorm(-0.36,0,1); Z #Es Z alpha/2
Z = qnorm(-0.36,0,1); Z #Es Z alpha/2
Z=0.64058
alphaedos = pnorm(Z,0,1)
alphaprima = (1-alphaedos)*2; alphaprima #Si me dan int y me preguntan alpha
gammaprima = 1-alphaprima; gammaprima#Si me dan int y me preguntan gamma (nivel confianza)
rm(list=ls())
Z = qnorm(0.36,0,1); Z #Es Z alpha/2
Z = qnorm(0.975,0,1); Z #Es Z alpha/2
Z = qnorm(0.64058,0,1); Z #Es Z alpha/2
Z = qnorm(0.64058,0,1); Z #Es Z alpha/2
alphaedos = pnorm(Z,0,1)
rm(list=ls())
alphaedos = pnorm(0.36,0,1) #F(0.36)=0.64058 --> Para calcular Probabilidades, errores tipo.
rm(list=ls())
#En hipótesis, se acepta H0 si:
#Bilateral: Zalpha/2 <= Zobs <= Zalpha/2; con p=2-2F(Zobs), si p >= alpha
#H0: mu = mu0, H1: mu != mu0
alpha = 0.05
n = 5 #Tamaño de la muestra, n-1 gl
t = qt(1-alpha/2, n-1); t #Es t alpha/2
#Hipótesis: tobs = (mean()-mu0)/(s/sqrt(n))
#Unilateral superior: Si tobs < talpha, o p >= alpha, se mantiene H0
t = qt(1-alpha,n-1); t #Esta es talpha
tobs=3,162
tobs=3.162
p = 1 - pt(tobs,n-1); p
rm(list=ls())
#Hipótesis: tobs = (mean()-mu0)/(s/sqrt(n)), con s siendo s(n-1)
#Unilateral superior: Si tobs < talpha, o p >= alpha, se mantiene H0
alpha = 0.01
t = qt(1-alpha,n-1); t #Esta es talpha
n = 6
t = qt(1-alpha,n-1); t #Esta es talpha
rm(list=ls())
#Hipótesis: tobs = (mean()-mu0)/(s/sqrt(n)), con s siendo s(n-1)
#Unilateral superior: Si tobs < talpha, o p >= alpha, se mantiene H0
alpha = 0.01
n = 6
#Unilateral inferior: Si tobs > talpha, o p >= alpha, se mantiene H0
t = qt(alpha,n-1); t #Esta es talpha
rm(list=ls())
alpha = 0.05 #Nivel de significación
Z = qnorm(1-alpha/2,0,1); Z #Es Z alpha/2, F^(-1)(0.975)=1,96
#Unilateral inferior: se acepta H0 si Zobs >= Zalpha, o p >= alpha
#H0: mu >=(=) mu0, H1: mu < mu0 (rechazo por abajo)
Z = qnorm(alpha,0,1); Z #Es Z alpha
p = pnorm(Zobs,0,1) #Es p = F(Zobs)
Zobs=-1.659
p = pnorm(Zobs,0,1) #Es p = F(Zobs)
Z=
rm(list=ls())
Z=0.347
alphaedos = pnorm(Z,0,1) #F(0.36)=0.64058 --> Para calcular Probabilidades, errores tipo.
alphaedos = 1-pnorm(Z,0,1) #F(0.36)=0.64058 --> Para calcular Probabilidades, errores tipo.
alphaedos = 1-pnorm(0.65,0,1) #F(0.36)=0.64058 --> Para calcular Probabilidades, errores tipo.
alphaedos = pnorm(0.65,0,1) #F(0.36)=0.64058 --> Para calcular Probabilidades, errores tipo.
alphaedos = pnorm(0.35,0,1) #F(0.36)=0.64058 --> Para calcular Probabilidades, errores tipo.
alphaedos = pnorm(0.35,0,1) #F(0.36)=0.64058 --> Para calcular Probabilidades, errores tipo.
p = pnorm(Z,0,1) #Es p = F(Zobs)
rm(list=ls())
Z=0.36
p = 1 - pnorm(Z,0,1) #Es p = 1 - F(Zobs)
Z=0.35
rm(list=ls())
Z=0.35
p = pnorm(Zobs,0,1) #Es p = F(Zobs)
p = pnorm(Z,0,1) #Es p = F(Zobs)
p = 1 - pnorm(Z,0,1) #Es p = 1 - F(Zobs)
p = pnorm(-0.36,0,1) #Es p = F(Zobs)
p = 1 - pnorm(0.65,0,1) #Es p = 1 - F(Zobs)
p = pnorm(0.35,0,1) #Es p = F(Zobs)
p = pnorm(0.35,0,1) #Es p = F(Zobs)
p = 1 - pnorm(0.65,0,1) #Es p = 1 - F(Zobs)
p = 1 - pnorm(0.35,0,1) #Es p = 1 - F(Zobs)
p = 1 - pnorm(-0.36,0,1) #Es p = 1 - F(Zobs)
p = pnorm(-0.36,0,1) #Es p = F(Zobs)
p = 1 - pnorm(0.35,0,1) #Es p = 1 - F(Zobs)
rm(list=ls())
alpha = 0.05
n = 15
#Var = σ^2, sd = σ
#En hipótesis, se acepta H0 si: (int de aceptación de H0: [aci,acd])
#Bilateral: aci <= chi2obs <= acd; con p=2-2F(Zobs), si p >= alpha
#H0: Var = Var0, H1: Var != Var0
aci = qchisq(alpha/2,n-1,lower.tail=TRUE) #Es aci, borde inferior
acd = qchisq(alpha/2,n-1,lower.tail=FALSE) #Es acd, borde superior
#Unilateral superior: se acepta H0 si chi2obs <= acd, o si p >= alpha, (-inf,acd]
#H0: Var <=(=) Var0, H1: Var > Var0 (rechazo arriba, a la dcha)
acd = qchisq(alpha/2,n-1,lower.tail=FALSE)
#Unilateral inferior: se acepta H0 si chi2obs >= aci, o p >= alpha, [aci,+inf)
#H0: Var >=(=) Var0, H1: Var < Var0 (rechazo por abajo)
aci = qchisq(1-alpha,n-1,lower.tail=TRUE)
#Unilateral superior: se acepta H0 si chi2obs <= acd, o si p >= alpha, (-inf,acd]
#H0: Var <=(=) Var0, H1: Var > Var0 (rechazo arriba, a la dcha)
acd = qchisq(alpha,n-1,lower.tail=FALSE)
#Unilateral inferior: se acepta H0 si chi2obs >= aci, o p >= alpha, [aci,+inf)
#H0: Var >=(=) Var0, H1: Var < Var0 (rechazo por abajo)
aci = qchisq(alpha,n-1,lower.tail=TRUE)
rm(list=ls())
6/sum(m^2)
m = c(2.6, 4.4, 3.6, 2.9, 2.3, 3.9)
6/sum(m^2)
multiply(m)
-sum(log(m))/6
#En hipótesis, se acepta H0 si (como Caso 1):
#Bilateral: Zalpha/2 <= Zobs <= Zalpha/2; con p=2-2F(Zobs), si p >= alpha
#H0: p=p0, H1: p != p0
n = 300
p0 = 0.03
pobs = 12/n
Zobs = (pobs-p0)/sqrt(p0*(1-p0)/n) #Este es el estadístico
n = 26
#Hipótesis: tobs = (mean()-mu0)/(s/sqrt(n)), con s siendo s(n-1)
#Unilateral superior: Si tobs < talpha, o p >= alpha, se mantiene H0
alpha = 0.01
#Unilateral inferior: Si tobs > talpha, o p >= alpha, se mantiene H0
t = qt(alpha,n-1); t #Esta es talpha
tobs=-2,777777777
p = pt(tobs,n-1); p
tobs=-2.777777777
p = pt(tobs,n-1); p
#Hipótesis: tobs = (mean()-mu0)/(s/sqrt(n)), con s siendo s(n-1)
#Unilateral superior: Si tobs < talpha, o p >= alpha, se mantiene H0
alpha = 0.02
n = 11
t = qt(1-alpha,n-1); t #Esta es talpha
rm(list=ls())
p = pt(-19.859154,9-1); p
rm(list=ls())
